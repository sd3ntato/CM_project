- mettere citazioni rel [v]
- non regolarizzare bias [x]
- chiedere a frangioni riguardo alla convessita supposta da bundle method [v]
- allenamento si deve fermare quando il gradiente e' piccolo. [v]
- capire come funziona il mio momento, se e' nesterov o classico, comunque se giusto o meno. [v]
- riguardare le slide sulla regolarizzazione del micheli e ricordare come funziona [v]
- capire e implementare regolarizzazione l1 [v]
- stop con grad/init_grad<eps [v]
- selezionare step-size con armijo-wolfe [v]
- inviare bozza a frangioni e poloni [v]
- abbozzare PBM [v]
- installare sto cvxpy [v]
- my flatten gli faccio dare vettori colonna, vedi se si rompe l'altro allenamento con momento [v]
- guarda, qui il calcolo della funzione loss non va bene, quindi mo riguarda quella io stacco ciao [v]
- esperimento regressione multi-dimensionale, o direttamente prova su test di ML [v]
- line-search e' backtracking, posso/ha senso usare entrambe le condizioni AW in backtracking? [v] c'e' scritto esattamente come fa nelle slide, fai quello pls
- qui bisogna capi come cazzo funziona sta cazzo de regolarizzazione, quando calcolo la norma i pesi li devo tene in forma matriciale o li mette a vettore?! [v] tutto a vettore


IDEE ESPERIMENTI:
- bundle method da solo credo si incastri su poor local minima certe volte per via della non-convessita


PENSIERI DUBBI PERPLESSITA':
- comunque il bundle method non funziona se uso come loss squared_error (senza mean), penso che sia per via della forte non convessita' della funzione quando usi una loss che assume valori cosi alti... [v] avevo solo sbagliato sqared err
- allora io direi che mo potemo comincia a scrive un po' de relazione e pensa a che fa come esperimenti, nel frattempo scrivi quelle due comande al frangioni e noi se beccamo domani [v]

COSA RIPASSARE:
- Ottimizzazione funzioni quadratiche con constraint
- Ripasso CG con Poloni (annessi e connessi)
- condition number of curvature at the minimum